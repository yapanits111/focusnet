{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f0c4e9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from detector import SSD_CBAM_MNV3\n",
    "from ssd_head import SSDLoss\n",
    "from transforms_lowlight import get_train_transforms, get_val_transforms\n",
    "from train import collate, HazardDataset\n",
    "\n",
    "img_size = 320\n",
    "num_classes = 1 + 4  # background + hazard classes\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "checkpoint_path = \"ssd_cbam_mnv3_lowlight.pt\"  # upload your last model\n",
    "\n",
    "# Load model\n",
    "model = SSD_CBAM_MNV3(num_classes=num_classes, img_size=img_size).to(device)\n",
    "ckpt = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_state_dict(ckpt['model'])\n",
    "print(\"Loaded weights from\", checkpoint_path)\n",
    "\n",
    "# Load merged dataset\n",
    "train_ds = HazardDataset(\n",
    "    img_dir=\"merged/train\",\n",
    "    ann_file=\"merged/train/_annotations.coco.json\",\n",
    "    transforms=get_train_transforms(img_size)\n",
    ")\n",
    "val_ds = HazardDataset(\n",
    "    img_dir=\"merged/valid\",\n",
    "    ann_file=\"merged/valid/_annotations.coco.json\",\n",
    "    transforms=get_val_transforms(img_size)\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=2, collate_fn=collate)\n",
    "val_loader = DataLoader(val_ds, batch_size=16, shuffle=False, num_workers=2, collate_fn=collate)\n",
    "\n",
    "loss_fn = SSDLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "best_val = float('inf')\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for images, targets in train_loader:\n",
    "        images = images.to(device)\n",
    "        targets = [{'boxes': t['boxes'].to(device), 'labels': t['labels'].to(device)} for t in targets]\n",
    "\n",
    "        cls_logits, box_deltas, anchors = model(images)\n",
    "        loss = loss_fn(cls_logits, box_deltas, anchors, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader:\n",
    "            images = images.to(device)\n",
    "            targets = [{'boxes': t['boxes'].to(device), 'labels': t['labels'].to(device)} for t in targets]\n",
    "            cls_logits, box_deltas, anchors = model(images)\n",
    "            loss = loss_fn(cls_logits, box_deltas, anchors, targets)\n",
    "            total_val_loss += loss.item()\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train {avg_train_loss:.4f} | Val {avg_val_loss:.4f}\")\n",
    "\n",
    "    if avg_val_loss < best_val:\n",
    "        best_val = avg_val_loss\n",
    "        torch.save({'model': model.state_dict()}, \"ssd_cbam_mnv3_lowlight_finetuned_merged.pt\")\n",
    "        print(\"Saved improved model\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
