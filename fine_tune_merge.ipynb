{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e165afc9",
   "metadata": {},
   "source": [
    "# FocusNet: Low-Light Road Hazard Detection\n",
    "\n",
    "## Step-by-Step Guide to Run FocusNet in Google Colab\n",
    "\n",
    "### Prerequisites:\n",
    "1. Google account with access to Google Drive and Google Colab\n",
    "2. Your dataset in COCO format\n",
    "3. The 5 essential FocusNet Python files\n",
    "\n",
    "### Step 1: Prepare Your Files\n",
    "Before opening Colab, make sure you have:\n",
    "- **Dataset**: Upload your COCO format dataset to Google Drive\n",
    "- **Python Files**: Download these 5 files to your computer:\n",
    "  - `backbone_cbam_mnv3.py`\n",
    "  - `cbam.py` \n",
    "  - `detector.py`\n",
    "  - `ssd_head.py`\n",
    "  - `transforms_lowlight.py`\n",
    "\n",
    "### Step 2: Open Google Colab\n",
    "1. Go to [colab.research.google.com](https://colab.research.google.com)\n",
    "2. Upload this notebook file or create a new notebook\n",
    "3. Go to **Runtime** ‚Üí **Change runtime type** \n",
    "4. Set **Hardware accelerator** to **GPU** (T4 recommended)\n",
    "5. Click **Save**\n",
    "\n",
    "### Step 3: Install Dependencies\n",
    "Run the cell below to install required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9052af2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Install Dependencies\n",
    "print(\"Installing required packages...\")\n",
    "\n",
    "# Install PyTorch with CUDA support\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# Install other required packages\n",
    "!pip install opencv-python-headless\n",
    "!pip install pillow\n",
    "!pip install matplotlib\n",
    "!pip install scikit-learn\n",
    "\n",
    "print(\"All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9596141",
   "metadata": {},
   "source": [
    "## Step 4: Load Python Files from Google Drive\n",
    "\n",
    "Upload your 5 essential FocusNet Python files to Google Drive, then load them safely to prevent losing them when Colab crashes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5043116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Define Google Drive path for your Python files\n",
    "GDRIVE_CODE_PATH = \"/content/drive/MyDrive/focusnet_code\"  # UPDATE THIS PATH!\n",
    "\n",
    "# Add the code directory to Python path\n",
    "sys.path.insert(0, GDRIVE_CODE_PATH)\n",
    "\n",
    "# Check if files exist in Google Drive\n",
    "required_files = ['backbone_cbam_mnv3.py', 'cbam.py', 'detector.py', 'ssd_head.py', 'transforms_lowlight.py']\n",
    "\n",
    "print(\"Checking for Python files in Google Drive...\")\n",
    "missing_files = []\n",
    "\n",
    "for filename in required_files:\n",
    "    filepath = os.path.join(GDRIVE_CODE_PATH, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        print(f\"‚úì Found: {filename}\")\n",
    "    else:\n",
    "        missing_files.append(filename)\n",
    "        print(f\"‚úó Missing: {filename}\")\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"\\n‚ö†Ô∏è Missing files: {missing_files}\")\n",
    "    print(f\"Please upload these files to Google Drive at: {GDRIVE_CODE_PATH}\")\n",
    "    \n",
    "    # Fallback: Upload files directly to Colab\n",
    "    print(\"\\nüìÅ Fallback: Upload files directly to Colab session\")\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    print(f\"üì§ Uploaded {len(uploaded)} files to current session:\")\n",
    "    for filename in uploaded.keys():\n",
    "        print(f\"  - {filename}\")\n",
    "else:\n",
    "    print(\"‚úÖ All Python files found in Google Drive!\")\n",
    "    print(\"üîí Files are safe from session crashes and will persist across sessions.\")\n",
    "\n",
    "print(f\"\\nüìÇ Code directory: {GDRIVE_CODE_PATH}\")\n",
    "print(\"üöÄ Python files ready to import!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f478a3d",
   "metadata": {},
   "source": [
    "## Step 5: Initialize FocusNet Model and Load Dataset\n",
    "\n",
    "Now let's set up the FocusNet model and prepare your dataset for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85b128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FocusNet: SSD + MobileNetV3 + CBAM for Low-Light Road Hazard Detection\n",
    "# Complete training and evaluation pipeline for thesis validation\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === MOUNT GOOGLE DRIVE FOR DATASET ACCESS ===\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print(\"üìÇ Google Drive mounted successfully!\")\n",
    "\n",
    "# === CORE FOCUSNET ARCHITECTURE IMPORTS ===\n",
    "# Import the 5 essential Python files we uploaded:\n",
    "try:\n",
    "    from backbone_cbam_mnv3 import MNV3BackboneWithCBAM\n",
    "    from cbam import CBAM, ChannelAttention, SpatialAttention  \n",
    "    from detector import SSD_CBAM_MNV3\n",
    "    from ssd_head import SSDHead\n",
    "    from transforms_lowlight import FocusNetTransforms\n",
    "    print(\"‚úÖ All FocusNet modules imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import Error: {e}\")\n",
    "    print(\"Please make sure all Python files are uploaded to Google Drive or current session\")\n",
    "\n",
    "# === DATASET CONFIGURATION ===\n",
    "# UPDATE THESE PATHS for your dataset location\n",
    "DATASET_BASE_PATH = \"/content/drive/MyDrive/your_dataset\"  # UPDATE THIS!\n",
    "TRAIN_IMG_DIR = f\"{DATASET_BASE_PATH}/images/train\"\n",
    "VAL_IMG_DIR = f\"{DATASET_BASE_PATH}/images/val\"  \n",
    "TRAIN_ANN_FILE = f\"{DATASET_BASE_PATH}/annotations/train.json\"\n",
    "VAL_ANN_FILE = f\"{DATASET_BASE_PATH}/annotations/val.json\"\n",
    "\n",
    "# === TRAINING CONFIGURATION ===\n",
    "BATCH_SIZE = 8  # Adjust based on your GPU memory\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 50\n",
    "NUM_CLASSES = 2  # Background + your object class (UPDATE if different)\n",
    "\n",
    "# === DEVICE CONFIGURATION ===\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üñ•Ô∏è Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è CUDA not available - using CPU (training will be slow)\")\n",
    "\n",
    "print(f\"üéØ FocusNet Configuration:\")\n",
    "print(f\"  - Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  - Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"  - Number of Classes: {NUM_CLASSES}\")\n",
    "print(f\"  - Training Epochs: {NUM_EPOCHS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5523369b",
   "metadata": {},
   "source": [
    "### Step 6: Training Function\n",
    "Now we'll define the training function for FocusNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a1251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Define Training and Evaluation Functions\n",
    "\n",
    "def train_one_epoch(model, loss_fn, loader, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    num_batches = len(loader)\n",
    "    \n",
    "    print(f\"Training Epoch {epoch}...\")\n",
    "    for i, (images, targets) in enumerate(loader):\n",
    "        images = images.to(device)\n",
    "        batch_targets = []\n",
    "        for t in targets:\n",
    "            bt = {'boxes': t['boxes'].to(device), 'labels': t['labels'].to(device)}\n",
    "            batch_targets.append(bt)\n",
    "        \n",
    "        cls_logits, box_deltas, anchors = model(images)\n",
    "        loss = loss_fn(cls_logits, box_deltas, anchors, batch_targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Print progress every 10 batches\n",
    "        if (i + 1) % 10 == 0:\n",
    "            avg_loss = total_loss / (i + 1)\n",
    "            print(f\"  Batch {i+1}/{num_batches}, Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    return total_loss / num_batches\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loss_fn, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    print(\"Evaluating...\")\n",
    "    for images, targets in loader:\n",
    "        images = images.to(device)\n",
    "        batch_targets = [{'boxes': t['boxes'].to(device), 'labels': t['labels'].to(device)} for t in targets]\n",
    "        \n",
    "        cls_logits, box_deltas, anchors = model(images)\n",
    "        loss = loss_fn(cls_logits, box_deltas, anchors, batch_targets)\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "print(\"Training functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367ba717",
   "metadata": {},
   "source": [
    "### Step 7: Start Training\n",
    "Now we'll train the FocusNet model. You can adjust the number of epochs based on your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff26684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Train FocusNet Model (with Crash Protection)\n",
    "\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "# Training configuration\n",
    "num_epochs = 10  # You can increase this for longer training\n",
    "best_val_loss = float('inf')\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Define backup paths\n",
    "GDRIVE_BACKUP_DIR = f\"{GDRIVE_DATASET_BASE}/training_backups\"\n",
    "os.makedirs(GDRIVE_BACKUP_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Starting FocusNet training for {num_epochs} epochs...\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Batch size: {train_loader.batch_size}\")\n",
    "print(f\"Automatic backups will be saved to: {GDRIVE_BACKUP_DIR}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    # Training\n",
    "    train_loss = train_one_epoch(model, loss_fn, train_loader, optimizer, device, epoch+1)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validation\n",
    "    val_loss = evaluate(model, loss_fn, val_loader, device)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # Save best model (local)\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        checkpoint = {\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'train_losses': train_losses,\n",
    "            'val_losses': val_losses\n",
    "        }\n",
    "        \n",
    "        # Save locally\n",
    "        torch.save(checkpoint, 'best_focusnet_model.pt')\n",
    "        print(f\"Saved best model (val_loss: {val_loss:.4f})\")\n",
    "        \n",
    "        # Automatic backup to Google Drive (crash protection)\n",
    "        backup_path = f\"{GDRIVE_BACKUP_DIR}/best_model_epoch_{epoch+1}.pt\"\n",
    "        shutil.copy('best_focusnet_model.pt', backup_path)\n",
    "        print(f\"Backup saved to Drive: best_model_epoch_{epoch+1}.pt\")\n",
    "    \n",
    "    # Save checkpoint every 5 epochs (additional protection)\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        checkpoint_path = f\"{GDRIVE_BACKUP_DIR}/checkpoint_epoch_{epoch+1}.pt\"\n",
    "        torch.save({\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'train_losses': train_losses,\n",
    "            'val_losses': val_losses\n",
    "        }, checkpoint_path)\n",
    "        print(f\"Checkpoint saved: checkpoint_epoch_{epoch+1}.pt\")\n",
    "        \n",
    "        # Plot training progress\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(train_losses, label='Train Loss', color='blue')\n",
    "        plt.plot(val_losses, label='Val Loss', color='red')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.title('FocusNet Training Progress')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(val_losses, label='Validation Loss', color='orange')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Validation Loss')\n",
    "        plt.title('Validation Loss Trend')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{GDRIVE_BACKUP_DIR}/training_progress_epoch_{epoch+1}.png')\n",
    "        plt.show()\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "print(\"Files saved:\")\n",
    "print(\"- best_focusnet_model.pt (local session)\")\n",
    "print(f\"- Multiple backups in: {GDRIVE_BACKUP_DIR}\")\n",
    "print(\"Your training is protected against crashes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00db2f49",
   "metadata": {},
   "source": [
    "### Step 8: Test the Trained Model\n",
    "Let's test our trained FocusNet model on some validation images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea84b814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Test FocusNet Model\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def decode_predictions(cls_logits, box_deltas, anchors, score_thresh=0.5, nms_thresh=0.45):\n",
    "    \"\"\"Decode model predictions into bounding boxes and scores\"\"\"\n",
    "    cls_scores = F.softmax(cls_logits, dim=-1)  # [B, A, C]\n",
    "    \n",
    "    # Get max scores and predicted classes\n",
    "    max_scores, pred_labels = cls_scores.max(dim=-1)  # [B, A]\n",
    "    \n",
    "    # Filter by score threshold and exclude background (class 0)\n",
    "    valid_mask = (max_scores > score_thresh) & (pred_labels > 0)\n",
    "    \n",
    "    results = []\n",
    "    for b in range(cls_logits.size(0)):\n",
    "        valid_b = valid_mask[b]\n",
    "        if not valid_b.any():\n",
    "            results.append(([], [], []))\n",
    "            continue\n",
    "            \n",
    "        scores_b = max_scores[b][valid_b]\n",
    "        labels_b = pred_labels[b][valid_b]\n",
    "        deltas_b = box_deltas[b][valid_b]\n",
    "        anchors_b = anchors[valid_b]\n",
    "        \n",
    "        # Decode boxes\n",
    "        pred_boxes = decode_boxes(anchors_b, deltas_b)\n",
    "        \n",
    "        results.append((pred_boxes.cpu(), labels_b.cpu(), scores_b.cpu()))\n",
    "    \n",
    "    return results\n",
    "\n",
    "def decode_boxes(anchors, deltas, center_variance=0.1, size_variance=0.2):\n",
    "    \"\"\"Decode box deltas to actual coordinates\"\"\"\n",
    "    cxcy = deltas[..., :2] * center_variance * anchors[..., :2] + anchors[..., :2]\n",
    "    wh = torch.exp(deltas[..., 2:] * size_variance) * anchors[..., 2:]\n",
    "    \n",
    "    # Convert to x1y1x2y2\n",
    "    x1y1 = cxcy - wh / 2\n",
    "    x2y2 = cxcy + wh / 2\n",
    "    \n",
    "    return torch.cat([x1y1, x2y2], dim=-1)\n",
    "\n",
    "def visualize_predictions(image_tensor, boxes, labels, scores, class_names=None):\n",
    "    \"\"\"Visualize predictions on image\"\"\"\n",
    "    # Convert tensor to numpy\n",
    "    if isinstance(image_tensor, torch.Tensor):\n",
    "        img = image_tensor.permute(1, 2, 0).cpu().numpy()\n",
    "        # Denormalize (assuming ImageNet normalization)\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "        img = img * std + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    # Draw bounding boxes\n",
    "    ax = plt.gca()\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        x1, y1, x2, y2 = box\n",
    "        # Convert normalized coords to pixel coords\n",
    "        h, w = img.shape[:2]\n",
    "        x1, y1, x2, y2 = x1*w, y1*h, x2*w, y2*h\n",
    "        \n",
    "        # Draw rectangle\n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, \n",
    "                           fill=False, color='red', linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Add label\n",
    "        label_text = f\"Class {label}: {score:.2f}\"\n",
    "        if class_names and label < len(class_names):\n",
    "            label_text = f\"{class_names[label]}: {score:.2f}\"\n",
    "        \n",
    "        plt.text(x1, y1-5, label_text, color='red', fontsize=10,\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='white', alpha=0.7))\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.title('FocusNet Predictions')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Load best model for testing\n",
    "print(\"Loading best trained model...\")\n",
    "checkpoint = torch.load('best_focusnet_model.pt', map_location=device)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.eval()\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Test on a few validation samples\n",
    "print(\"Testing FocusNet on validation samples...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Get a batch from validation loader\n",
    "    for images, targets in val_loader:\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # Make predictions\n",
    "        cls_logits, box_deltas, anchors = model(images)\n",
    "        \n",
    "        # Decode predictions\n",
    "        predictions = decode_predictions(cls_logits, box_deltas, anchors, \n",
    "                                       score_thresh=0.3, nms_thresh=0.45)\n",
    "        \n",
    "        # Visualize first 3 images from the batch\n",
    "        for i in range(min(3, len(images))):\n",
    "            boxes, labels, scores = predictions[i]\n",
    "            \n",
    "            print(f\"\\nSample {i+1}:\")\n",
    "            print(f\"Detected {len(boxes)} objects\")\n",
    "            \n",
    "            # Get class names from dataset\n",
    "            class_names = ['background'] + [cat['name'] for cat in val_ds.categories.values()]\n",
    "            \n",
    "            # Visualize\n",
    "            visualize_predictions(images[i], boxes, labels, scores, class_names)\n",
    "            \n",
    "            # Print detection details\n",
    "            if len(boxes) > 0:\n",
    "                for j, (box, label, score) in enumerate(zip(boxes, labels, scores)):\n",
    "                    class_name = class_names[label] if label < len(class_names) else f\"Class {label}\"\n",
    "                    print(f\"  Detection {j+1}: {class_name} (confidence: {score:.3f})\")\n",
    "            else:\n",
    "                print(\"  No objects detected\")\n",
    "        \n",
    "        break  # Only test first batch\n",
    "\n",
    "print(\"Testing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70626ac6",
   "metadata": {},
   "source": [
    "### Step 9: Download Your Trained Model\n",
    "Save your trained FocusNet model to your computer and optionally to Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3817b1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Download and Save Your Trained Model\n",
    "\n",
    "# Download the model file to your computer\n",
    "from google.colab import files\n",
    "files.download('best_focusnet_model.pt')\n",
    "print(\"Model downloaded to your computer!\")\n",
    "\n",
    "# Optional: Also save to Google Drive for backup\n",
    "import shutil\n",
    "\n",
    "save_to_drive = input(\"Save model to Google Drive as backup? (y/n): \").lower().strip()\n",
    "if save_to_drive == 'y':\n",
    "    drive_backup_path = f\"{GDRIVE_DATASET_BASE}/best_focusnet_model.pt\"\n",
    "    shutil.copy('best_focusnet_model.pt', drive_backup_path)\n",
    "    print(f\"Model also saved to Google Drive: {drive_backup_path}\")\n",
    "\n",
    "# Display final training summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FOCUSNET TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Architecture: SSD + MobileNetV3 + CBAM\")\n",
    "print(f\"Total epochs trained: {num_epochs}\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Dataset: {len(train_ds)} training + {len(val_ds)} validation samples\")\n",
    "print(f\"Classes: {len(train_ds.categories)} hazard categories\")\n",
    "print(\"\\nFiles created:\")\n",
    "print(\"- best_focusnet_model.pt (downloaded to your computer)\")\n",
    "if save_to_drive == 'y':\n",
    "    print(\"- best_focusnet_model.pt (backed up to Google Drive)\")\n",
    "print(\"\\nYour FocusNet model is ready for low-light road hazard detection!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
