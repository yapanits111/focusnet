{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e165afc9",
   "metadata": {},
   "source": [
    "# FocusNet: Low-Light Road Hazard Detection\n",
    "\n",
    "## Step-by-Step Guide to Run FocusNet in Google Colab\n",
    "\n",
    "### Prerequisites:\n",
    "1. Google account with access to Google Drive and Google Colab\n",
    "2. Your dataset in COCO format\n",
    "3. The 5 essential FocusNet Python files\n",
    "\n",
    "### Step 1: Prepare Your Files\n",
    "Before opening Colab, make sure you have:\n",
    "- **Dataset**: Upload your COCO format dataset to Google Drive\n",
    "- **Python Files**: Download these 5 files to your computer:\n",
    "  - `backbone_cbam_mnv3.py`\n",
    "  - `cbam.py` \n",
    "  - `detector.py`\n",
    "  - `ssd_head.py`\n",
    "  - `transforms_lowlight.py`\n",
    "\n",
    "### Step 2: Open Google Colab\n",
    "1. Go to [colab.research.google.com](https://colab.research.google.com)\n",
    "2. Upload this notebook file or create a new notebook\n",
    "3. Go to **Runtime** â†’ **Change runtime type** \n",
    "4. Set **Hardware accelerator** to **GPU** (T4 recommended)\n",
    "5. Click **Save**\n",
    "\n",
    "### Step 3: Install Dependencies\n",
    "Run the cell below to install required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9052af2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Install Dependencies\n",
    "print(\"Installing required packages...\")\n",
    "\n",
    "# Install PyTorch with CUDA support\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# Install other required packages\n",
    "!pip install opencv-python-headless\n",
    "!pip install pillow\n",
    "!pip install matplotlib\n",
    "!pip install scikit-learn\n",
    "\n",
    "print(\"All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb854461",
   "metadata": {},
   "source": [
    "### Step 4: Upload Python Files\n",
    "Upload the 5 essential FocusNet Python files to Colab. Click the upload button below and select all 5 files:\n",
    "- `backbone_cbam_mnv3.py`\n",
    "- `cbam.py`\n",
    "- `detector.py` \n",
    "- `ssd_head.py`\n",
    "- `transforms_lowlight.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fbf2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Upload Python Files\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Upload the 5 FocusNet Python files:\")\n",
    "print(\"1. backbone_cbam_mnv3.py\")\n",
    "print(\"2. cbam.py\")\n",
    "print(\"3. detector.py\")\n",
    "print(\"4. ssd_head.py\") \n",
    "print(\"5. transforms_lowlight.py\")\n",
    "print(\"\\nClick the upload button below:\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "print(f\"Successfully uploaded {len(uploaded)} files:\")\n",
    "for filename in uploaded.keys():\n",
    "    print(f\"  - {filename}\")\n",
    "\n",
    "# Verify all required files are uploaded\n",
    "required_files = ['backbone_cbam_mnv3.py', 'cbam.py', 'detector.py', 'ssd_head.py', 'transforms_lowlight.py']\n",
    "missing_files = [f for f in required_files if f not in uploaded]\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"Missing files: {missing_files}\")\n",
    "    print(\"Please upload the missing files before continuing.\")\n",
    "else:\n",
    "    print(\"All required files uploaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9596141",
   "metadata": {},
   "source": [
    "# Step 4: Load Python Files from Google Drive (Crash-Resistant)\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Define Google Drive path for your Python files\n",
    "GDRIVE_CODE_PATH = \"/content/drive/MyDrive/focusnet_code\"  # UPDATE THIS PATH!\n",
    "\n",
    "# Add the code directory to Python path\n",
    "sys.path.insert(0, GDRIVE_CODE_PATH)\n",
    "\n",
    "# Check if files exist in Google Drive\n",
    "required_files = ['backbone_cbam_mnv3.py', 'cbam.py', 'detector.py', 'ssd_head.py', 'transforms_lowlight.py']\n",
    "\n",
    "print(\"Checking for Python files in Google Drive...\")\n",
    "missing_files = []\n",
    "\n",
    "for filename in required_files:\n",
    "    filepath = os.path.join(GDRIVE_CODE_PATH, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        print(f\"Found: {filename}\")\n",
    "    else:\n",
    "        missing_files.append(filename)\n",
    "        print(f\"Missing: {filename}\")\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"\\nMissing files: {missing_files}\")\n",
    "    print(f\"Please upload these files to Google Drive at: {GDRIVE_CODE_PATH}\")\n",
    "    \n",
    "    # Fallback: Upload files directly to Colab\n",
    "    print(\"\\nFallback: Upload files directly to Colab session\")\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    print(f\"Uploaded {len(uploaded)} files to current session:\")\n",
    "    for filename in uploaded.keys():\n",
    "        print(f\"  - {filename}\")\n",
    "else:\n",
    "    print(\"All Python files found in Google Drive!\")\n",
    "    print(\"Files are safe from session crashes and will persist across sessions.\")\n",
    "\n",
    "print(f\"\\nCode directory: {GDRIVE_CODE_PATH}\")\n",
    "print(\"Python files will be imported from Google Drive (crash-resistant).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f0c4e9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Step 6: Initialize FocusNet Model and Load Dataset\n",
    "\n",
    "# FocusNet: SSD + MobileNetV3 + CBAM for Low-Light Road Hazard Detection\n",
    "# Complete training and evaluation pipeline for thesis validation\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === MOUNT GOOGLE DRIVE FOR DATASET ACCESS ===\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print(\"Google Drive mounted successfully!\")\n",
    "\n",
    "# === CORE FOCUSNET ARCHITECTURE IMPORTS ===\n",
    "# Import the 5 essential Python files we uploaded:\n",
    "from backbone_cbam_mnv3 import MNV3BackboneWithCBAM\n",
    "from cbam import CBAM, ChannelAttention, SpatialAttention  \n",
    "from detector import SSD_CBAM_MNV3\n",
    "from ssd_head import SSDHead, SSDLoss, make_anchor_grid, cxcywh_to_xyxy\n",
    "from transforms_lowlight import (\n",
    "    get_focusnet_train_transforms, \n",
    "    get_focusnet_eval_transforms,\n",
    "    get_thesis_test_transforms,\n",
    "    get_focusnet_input_specs\n",
    ")\n",
    "\n",
    "print(\"Successfully imported all FocusNet components!\")\n",
    "\n",
    "# === DATASET HANDLER (Inline Implementation) ===\n",
    "class HazardDataset:\n",
    "    \"\"\"COCO format dataset for road hazard detection (0.5-10 lux conditions)\"\"\"\n",
    "    \n",
    "    def __init__(self, img_dir, ann_file, transforms=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        with open(ann_file, 'r') as f:\n",
    "            self.coco_data = json.load(f)\n",
    "        \n",
    "        self.images = {img['id']: img for img in self.coco_data['images']}\n",
    "        self.categories = {cat['id']: cat for cat in self.coco_data['categories']}\n",
    "        \n",
    "        # Group annotations by image_id\n",
    "        self.img_to_anns = {}\n",
    "        for ann in self.coco_data['annotations']:\n",
    "            img_id = ann['image_id']\n",
    "            if img_id not in self.img_to_anns:\n",
    "                self.img_to_anns[img_id] = []\n",
    "            self.img_to_anns[img_id].append(ann)\n",
    "        \n",
    "        self.image_ids = list(self.images.keys())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.image_ids[idx]\n",
    "        img_info = self.images[img_id]\n",
    "        \n",
    "        # Load image\n",
    "        img_path = os.path.join(self.img_dir, img_info['file_name'])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Get annotations\n",
    "        anns = self.img_to_anns.get(img_id, [])\n",
    "        \n",
    "        boxes = []\n",
    "        labels = []\n",
    "        \n",
    "        img_width = img_info['width']\n",
    "        img_height = img_info['height']\n",
    "        \n",
    "        for ann in anns:\n",
    "            # Convert COCO bbox (x,y,w,h) to normalized (x1,y1,x2,y2)\n",
    "            x, y, w, h = ann['bbox']\n",
    "            x1 = x / img_width\n",
    "            y1 = y / img_height  \n",
    "            x2 = (x + w) / img_width\n",
    "            y2 = (y + h) / img_height\n",
    "            \n",
    "            # Clamp and validate\n",
    "            x1, y1, x2, y2 = max(0, x1), max(0, y1), min(1, x2), min(1, y2)\n",
    "            \n",
    "            if x2 > x1 and y2 > y1:\n",
    "                boxes.append([x1, y1, x2, y2])\n",
    "                labels.append(ann['category_id'])\n",
    "        \n",
    "        # Convert to tensors\n",
    "        if len(boxes) == 0:\n",
    "            boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            labels = torch.zeros((0,), dtype=torch.long)\n",
    "        else:\n",
    "            boxes = torch.tensor(boxes, dtype=torch.float32)\n",
    "            labels = torch.tensor(labels, dtype=torch.long)\n",
    "        \n",
    "        target = {'boxes': boxes, 'labels': labels}\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        return image, target\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Collate function for DataLoader\"\"\"\n",
    "    imgs, targets = zip(*batch)\n",
    "    return torch.stack(imgs, dim=0), list(targets)\n",
    "\n",
    "# === FOCUSNET CONFIGURATION ===\n",
    "print(\"FocusNet Architecture Configuration:\")\n",
    "specs = get_focusnet_input_specs()\n",
    "for key, value in specs.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# === MODEL SETUP ===\n",
    "img_size = 320\n",
    "num_classes = 1 + 4  # background + 4 hazard classes (potholes, humps, pedestrians, animals, roadworks)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nDevice: {device}\")\n",
    "\n",
    "# Initialize FocusNet model\n",
    "model = SSD_CBAM_MNV3(num_classes=num_classes, img_size=img_size).to(device)\n",
    "print(f\"FocusNet Model Initialized\")\n",
    "print(f\"   Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"   Trainable: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "# === GOOGLE DRIVE DATASET PATHS ===\n",
    "# UPDATE THIS PATH to match your Google Drive dataset location!\n",
    "GDRIVE_DATASET_BASE = \"/content/drive/MyDrive/focusnet_dataset\"  # CHANGE THIS!\n",
    "\n",
    "TRAIN_IMG_DIR = f\"{GDRIVE_DATASET_BASE}/train\"  \n",
    "TRAIN_ANN_FILE = f\"{GDRIVE_DATASET_BASE}/train/_annotations.coco.json\"\n",
    "VAL_IMG_DIR = f\"{GDRIVE_DATASET_BASE}/valid\"\n",
    "VAL_ANN_FILE = f\"{GDRIVE_DATASET_BASE}/valid/_annotations.coco.json\"\n",
    "\n",
    "print(f\"\\nDataset path: {GDRIVE_DATASET_BASE}\")\n",
    "print(\"If this path is incorrect, update GDRIVE_DATASET_BASE above!\")\n",
    "\n",
    "# Check if dataset paths exist\n",
    "print(f\"\\nChecking Google Drive dataset paths...\")\n",
    "paths_to_check = [GDRIVE_DATASET_BASE, TRAIN_IMG_DIR, VAL_IMG_DIR, TRAIN_ANN_FILE, VAL_ANN_FILE]\n",
    "for path in paths_to_check:\n",
    "    if os.path.exists(path):\n",
    "        print(f\"Found: {path}\")\n",
    "        if path.endswith('.json'):\n",
    "            # Count annotations for JSON files\n",
    "            try:\n",
    "                with open(path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                print(f\"   â†’ Images: {len(data.get('images', []))}, Annotations: {len(data.get('annotations', []))}\")\n",
    "            except:\n",
    "                pass\n",
    "        elif os.path.isdir(path):\n",
    "            # Count images for directories\n",
    "            img_count = len([f for f in os.listdir(path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "            print(f\"   â†’ Contains {img_count} images\")\n",
    "    else:\n",
    "        print(f\"Missing: {path}\")\n",
    "\n",
    "# Load pre-trained weights if available (from Google Drive)\n",
    "checkpoint_path = f\"{GDRIVE_DATASET_BASE}/ssd_cbam_mnv3_lowlight.pt\"  # Update path as needed\n",
    "try:\n",
    "    ckpt = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(ckpt['model'])\n",
    "    print(f\"Loaded pre-trained weights from Google Drive: {checkpoint_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Pre-trained weights not found in Google Drive. Training from scratch.\")\n",
    "\n",
    "# === DATASET SETUP ===\n",
    "print(f\"\\nSetting up datasets from Google Drive...\")\n",
    "try:\n",
    "    # Use FocusNet-specific transforms (thesis-aligned)\n",
    "    train_ds = HazardDataset(\n",
    "        img_dir=TRAIN_IMG_DIR,\n",
    "        ann_file=TRAIN_ANN_FILE,\n",
    "        transforms=get_focusnet_train_transforms(img_size)\n",
    "    )\n",
    "    \n",
    "    val_ds = HazardDataset(\n",
    "        img_dir=VAL_IMG_DIR,\n",
    "        ann_file=VAL_ANN_FILE,\n",
    "        transforms=get_focusnet_eval_transforms(img_size)  # RAW image evaluation\n",
    "    )\n",
    "    \n",
    "    print(f\"Datasets created successfully from Google Drive!\")\n",
    "    print(f\"   Train samples: {len(train_ds)}\")\n",
    "    print(f\"   Val samples: {len(val_ds)}\")\n",
    "    print(f\"   Categories: {len(train_ds.categories)}\")\n",
    "    \n",
    "    # Print category information\n",
    "    print(f\"   Category mapping:\")\n",
    "    for cat_id, cat_info in train_ds.categories.items():\n",
    "        print(f\"     {cat_id}: {cat_info['name']}\")\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=2, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_ds, batch_size=16, shuffle=False, num_workers=2, collate_fn=collate_fn)\n",
    "    \n",
    "    print(\"Data loaders created successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Dataset setup failed: {e}\")\n",
    "    print(f\"Please check that your dataset is properly uploaded to Google Drive at:\")\n",
    "    print(f\"  {GDRIVE_DATASET_BASE}\")\n",
    "    print(f\"And update the GDRIVE_DATASET_BASE path above.\")\n",
    "    raise e\n",
    "\n",
    "# === TRAINING SETUP ===\n",
    "loss_fn = SSDLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "print(f\"\\nReady for FocusNet training!\")\n",
    "print(f\"   Loss function: SSDLoss\")\n",
    "print(f\"   Optimizer: AdamW (lr=1e-4)\")\n",
    "print(f\"   Architecture: SSD + MobileNetV3 + CBAM\")\n",
    "print(f\"   Target: Low-light road hazard detection (0.5-10 lux)\")\n",
    "print(f\"   Data source: Google Drive mounted dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c6cfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session Recovery Function (Run this if your session crashes)\n",
    "\n",
    "def recover_from_crash():\n",
    "    \"\"\"\n",
    "    Call this function if your Colab session crashes and you need to resume training\n",
    "    \"\"\"\n",
    "    print(\"ðŸ”„ Recovering from session crash...\")\n",
    "    \n",
    "    # Re-mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    \n",
    "    # Re-add code path\n",
    "    import sys\n",
    "    GDRIVE_CODE_PATH = \"/content/drive/MyDrive/focusnet_code\"\n",
    "    if GDRIVE_CODE_PATH not in sys.path:\n",
    "        sys.path.insert(0, GDRIVE_CODE_PATH)\n",
    "    \n",
    "    # Check for backups\n",
    "    GDRIVE_BACKUP_DIR = f\"{GDRIVE_DATASET_BASE}/training_backups\"\n",
    "    \n",
    "    if os.path.exists(GDRIVE_BACKUP_DIR):\n",
    "        backup_files = [f for f in os.listdir(GDRIVE_BACKUP_DIR) if f.endswith('.pt')]\n",
    "        backup_files.sort()\n",
    "        \n",
    "        print(f\"Found {len(backup_files)} backup files:\")\n",
    "        for i, backup in enumerate(backup_files):\n",
    "            print(f\"  {i+1}. {backup}\")\n",
    "        \n",
    "        if backup_files:\n",
    "            latest_backup = backup_files[-1]\n",
    "            print(f\"\\nLatest backup: {latest_backup}\")\n",
    "            print(\"To resume training, load this backup in your model initialization cell.\")\n",
    "            return os.path.join(GDRIVE_BACKUP_DIR, latest_backup)\n",
    "    \n",
    "    print(\"No backups found. You'll need to start training from scratch.\")\n",
    "    return None\n",
    "\n",
    "# Uncomment the line below if you need to recover from a crash\n",
    "# recovery_path = recover_from_crash()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5523369b",
   "metadata": {},
   "source": [
    "### Step 7: Training Function\n",
    "Now we'll define the training function for FocusNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a1251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Define Training and Evaluation Functions\n",
    "\n",
    "def train_one_epoch(model, loss_fn, loader, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    num_batches = len(loader)\n",
    "    \n",
    "    print(f\"Training Epoch {epoch}...\")\n",
    "    for i, (images, targets) in enumerate(loader):\n",
    "        images = images.to(device)\n",
    "        batch_targets = []\n",
    "        for t in targets:\n",
    "            bt = {'boxes': t['boxes'].to(device), 'labels': t['labels'].to(device)}\n",
    "            batch_targets.append(bt)\n",
    "        \n",
    "        cls_logits, box_deltas, anchors = model(images)\n",
    "        loss = loss_fn(cls_logits, box_deltas, anchors, batch_targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Print progress every 10 batches\n",
    "        if (i + 1) % 10 == 0:\n",
    "            avg_loss = total_loss / (i + 1)\n",
    "            print(f\"  Batch {i+1}/{num_batches}, Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    return total_loss / num_batches\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loss_fn, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    print(\"Evaluating...\")\n",
    "    for images, targets in loader:\n",
    "        images = images.to(device)\n",
    "        batch_targets = [{'boxes': t['boxes'].to(device), 'labels': t['labels'].to(device)} for t in targets]\n",
    "        \n",
    "        cls_logits, box_deltas, anchors = model(images)\n",
    "        loss = loss_fn(cls_logits, box_deltas, anchors, batch_targets)\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "print(\"Training functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367ba717",
   "metadata": {},
   "source": [
    "### Step 8: Start Training\n",
    "Now we'll train the FocusNet model. You can adjust the number of epochs based on your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff26684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Train FocusNet Model (with Crash Protection)\n",
    "\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "# Training configuration\n",
    "num_epochs = 10  # You can increase this for longer training\n",
    "best_val_loss = float('inf')\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Define backup paths\n",
    "GDRIVE_BACKUP_DIR = f\"{GDRIVE_DATASET_BASE}/training_backups\"\n",
    "os.makedirs(GDRIVE_BACKUP_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Starting FocusNet training for {num_epochs} epochs...\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Batch size: {train_loader.batch_size}\")\n",
    "print(f\"Automatic backups will be saved to: {GDRIVE_BACKUP_DIR}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    # Training\n",
    "    train_loss = train_one_epoch(model, loss_fn, train_loader, optimizer, device, epoch+1)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validation\n",
    "    val_loss = evaluate(model, loss_fn, val_loader, device)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # Save best model (local)\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        checkpoint = {\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'train_losses': train_losses,\n",
    "            'val_losses': val_losses\n",
    "        }\n",
    "        \n",
    "        # Save locally\n",
    "        torch.save(checkpoint, 'best_focusnet_model.pt')\n",
    "        print(f\"Saved best model (val_loss: {val_loss:.4f})\")\n",
    "        \n",
    "        # Automatic backup to Google Drive (crash protection)\n",
    "        backup_path = f\"{GDRIVE_BACKUP_DIR}/best_model_epoch_{epoch+1}.pt\"\n",
    "        shutil.copy('best_focusnet_model.pt', backup_path)\n",
    "        print(f\"Backup saved to Drive: best_model_epoch_{epoch+1}.pt\")\n",
    "    \n",
    "    # Save checkpoint every 5 epochs (additional protection)\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        checkpoint_path = f\"{GDRIVE_BACKUP_DIR}/checkpoint_epoch_{epoch+1}.pt\"\n",
    "        torch.save({\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'train_losses': train_losses,\n",
    "            'val_losses': val_losses\n",
    "        }, checkpoint_path)\n",
    "        print(f\"Checkpoint saved: checkpoint_epoch_{epoch+1}.pt\")\n",
    "        \n",
    "        # Plot training progress\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(train_losses, label='Train Loss', color='blue')\n",
    "        plt.plot(val_losses, label='Val Loss', color='red')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.title('FocusNet Training Progress')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(val_losses, label='Validation Loss', color='orange')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Validation Loss')\n",
    "        plt.title('Validation Loss Trend')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{GDRIVE_BACKUP_DIR}/training_progress_epoch_{epoch+1}.png')\n",
    "        plt.show()\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "print(\"Files saved:\")\n",
    "print(\"- best_focusnet_model.pt (local session)\")\n",
    "print(f\"- Multiple backups in: {GDRIVE_BACKUP_DIR}\")\n",
    "print(\"Your training is protected against crashes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00db2f49",
   "metadata": {},
   "source": [
    "### Step 9: Test the Trained Model\n",
    "Let's test our trained FocusNet model on some validation images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea84b814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Test FocusNet Model\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def decode_predictions(cls_logits, box_deltas, anchors, score_thresh=0.5, nms_thresh=0.45):\n",
    "    \"\"\"Decode model predictions into bounding boxes and scores\"\"\"\n",
    "    cls_scores = F.softmax(cls_logits, dim=-1)  # [B, A, C]\n",
    "    \n",
    "    # Get max scores and predicted classes\n",
    "    max_scores, pred_labels = cls_scores.max(dim=-1)  # [B, A]\n",
    "    \n",
    "    # Filter by score threshold and exclude background (class 0)\n",
    "    valid_mask = (max_scores > score_thresh) & (pred_labels > 0)\n",
    "    \n",
    "    results = []\n",
    "    for b in range(cls_logits.size(0)):\n",
    "        valid_b = valid_mask[b]\n",
    "        if not valid_b.any():\n",
    "            results.append(([], [], []))\n",
    "            continue\n",
    "            \n",
    "        scores_b = max_scores[b][valid_b]\n",
    "        labels_b = pred_labels[b][valid_b]\n",
    "        deltas_b = box_deltas[b][valid_b]\n",
    "        anchors_b = anchors[valid_b]\n",
    "        \n",
    "        # Decode boxes\n",
    "        pred_boxes = decode_boxes(anchors_b, deltas_b)\n",
    "        \n",
    "        results.append((pred_boxes.cpu(), labels_b.cpu(), scores_b.cpu()))\n",
    "    \n",
    "    return results\n",
    "\n",
    "def decode_boxes(anchors, deltas, center_variance=0.1, size_variance=0.2):\n",
    "    \"\"\"Decode box deltas to actual coordinates\"\"\"\n",
    "    cxcy = deltas[..., :2] * center_variance * anchors[..., :2] + anchors[..., :2]\n",
    "    wh = torch.exp(deltas[..., 2:] * size_variance) * anchors[..., 2:]\n",
    "    \n",
    "    # Convert to x1y1x2y2\n",
    "    x1y1 = cxcy - wh / 2\n",
    "    x2y2 = cxcy + wh / 2\n",
    "    \n",
    "    return torch.cat([x1y1, x2y2], dim=-1)\n",
    "\n",
    "def visualize_predictions(image_tensor, boxes, labels, scores, class_names=None):\n",
    "    \"\"\"Visualize predictions on image\"\"\"\n",
    "    # Convert tensor to numpy\n",
    "    if isinstance(image_tensor, torch.Tensor):\n",
    "        img = image_tensor.permute(1, 2, 0).cpu().numpy()\n",
    "        # Denormalize (assuming ImageNet normalization)\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "        img = img * std + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    # Draw bounding boxes\n",
    "    ax = plt.gca()\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        x1, y1, x2, y2 = box\n",
    "        # Convert normalized coords to pixel coords\n",
    "        h, w = img.shape[:2]\n",
    "        x1, y1, x2, y2 = x1*w, y1*h, x2*w, y2*h\n",
    "        \n",
    "        # Draw rectangle\n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, \n",
    "                           fill=False, color='red', linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Add label\n",
    "        label_text = f\"Class {label}: {score:.2f}\"\n",
    "        if class_names and label < len(class_names):\n",
    "            label_text = f\"{class_names[label]}: {score:.2f}\"\n",
    "        \n",
    "        plt.text(x1, y1-5, label_text, color='red', fontsize=10,\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='white', alpha=0.7))\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.title('FocusNet Predictions')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Load best model for testing\n",
    "print(\"Loading best trained model...\")\n",
    "checkpoint = torch.load('best_focusnet_model.pt', map_location=device)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.eval()\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Test on a few validation samples\n",
    "print(\"Testing FocusNet on validation samples...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Get a batch from validation loader\n",
    "    for images, targets in val_loader:\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # Make predictions\n",
    "        cls_logits, box_deltas, anchors = model(images)\n",
    "        \n",
    "        # Decode predictions\n",
    "        predictions = decode_predictions(cls_logits, box_deltas, anchors, \n",
    "                                       score_thresh=0.3, nms_thresh=0.45)\n",
    "        \n",
    "        # Visualize first 3 images from the batch\n",
    "        for i in range(min(3, len(images))):\n",
    "            boxes, labels, scores = predictions[i]\n",
    "            \n",
    "            print(f\"\\nSample {i+1}:\")\n",
    "            print(f\"Detected {len(boxes)} objects\")\n",
    "            \n",
    "            # Get class names from dataset\n",
    "            class_names = ['background'] + [cat['name'] for cat in val_ds.categories.values()]\n",
    "            \n",
    "            # Visualize\n",
    "            visualize_predictions(images[i], boxes, labels, scores, class_names)\n",
    "            \n",
    "            # Print detection details\n",
    "            if len(boxes) > 0:\n",
    "                for j, (box, label, score) in enumerate(zip(boxes, labels, scores)):\n",
    "                    class_name = class_names[label] if label < len(class_names) else f\"Class {label}\"\n",
    "                    print(f\"  Detection {j+1}: {class_name} (confidence: {score:.3f})\")\n",
    "            else:\n",
    "                print(\"  No objects detected\")\n",
    "        \n",
    "        break  # Only test first batch\n",
    "\n",
    "print(\"Testing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70626ac6",
   "metadata": {},
   "source": [
    "### Step 10: Download Your Trained Model\n",
    "Save your trained FocusNet model to your computer and optionally to Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3817b1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Download and Save Your Trained Model\n",
    "\n",
    "# Download the model file to your computer\n",
    "from google.colab import files\n",
    "files.download('best_focusnet_model.pt')\n",
    "print(\"Model downloaded to your computer!\")\n",
    "\n",
    "# Optional: Also save to Google Drive for backup\n",
    "import shutil\n",
    "\n",
    "save_to_drive = input(\"Save model to Google Drive as backup? (y/n): \").lower().strip()\n",
    "if save_to_drive == 'y':\n",
    "    drive_backup_path = f\"{GDRIVE_DATASET_BASE}/best_focusnet_model.pt\"\n",
    "    shutil.copy('best_focusnet_model.pt', drive_backup_path)\n",
    "    print(f\"Model also saved to Google Drive: {drive_backup_path}\")\n",
    "\n",
    "# Display final training summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FOCUSNET TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Architecture: SSD + MobileNetV3 + CBAM\")\n",
    "print(f\"Total epochs trained: {num_epochs}\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Dataset: {len(train_ds)} training + {len(val_ds)} validation samples\")\n",
    "print(f\"Classes: {len(train_ds.categories)} hazard categories\")\n",
    "print(\"\\nFiles created:\")\n",
    "print(\"- best_focusnet_model.pt (downloaded to your computer)\")\n",
    "if save_to_drive == 'y':\n",
    "    print(\"- best_focusnet_model.pt (backed up to Google Drive)\")\n",
    "print(\"\\nYour FocusNet model is ready for low-light road hazard detection!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
